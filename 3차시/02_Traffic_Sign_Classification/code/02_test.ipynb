{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Traffic Sign Classification - ëª¨ë¸ í‰ê°€\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ë‹¤ì–‘í•œ ì§€í‘œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "## í‰ê°€ ê³¼ì •\n",
    "1. í™˜ê²½ ì„¤ì • ë° í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ\n",
    "2. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "3. ëª¨ë¸ í‰ê°€ ìˆ˜í–‰\n",
    "4. ì„±ëŠ¥ ì§€í‘œ ë¶„ì„ (Accuracy, Precision, Recall, F1-Score)\n",
    "5. Confusion Matrix ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install transformers pillow torch torchvision scikit-learn matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Drive ë§ˆìš´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì‘ì—… ë””ë ‰í† ë¦¬ ë° ëª¨ë¸ ê²½ë¡œ ì„¤ì •\n",
    "\n",
    "**ì¤‘ìš”**: `WORK_DIR`ì„ ë³¸ì¸ì˜ Google Drive ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive ë‚´ ì‘ì—… ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "WORK_DIR = '/content/drive/MyDrive/2026_AI_Advanced_Study-main/3ì°¨ì‹œ/02_Traffic_Sign_Classification'\n",
    "\n",
    "# í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ê³ ì •)\n",
    "MODEL_PATH = os.path.join(WORK_DIR, 'runs/classification/final_model')\n",
    "\n",
    "# ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "\n",
    "# ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(f\"âœ… ëª¨ë¸ ë°œê²¬: {MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}\")\n",
    "    print(\"   ë¨¼ì € 01_train.ipynbë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDataset(TorchDataset):\n",
    "    \"\"\"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, processor=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.processor = processor\n",
    "        self.samples = []\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ì§‘\n",
    "        for class_idx in range(5):\n",
    "            class_dir = self.data_dir / f'class_{class_idx}'\n",
    "            if class_dir.exists():\n",
    "                for img_path in sorted(class_dir.glob('*.jpg')):\n",
    "                    self.samples.append((img_path, class_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        return {'image': image, 'label': label}\n",
    "\n",
    "print(\"âœ… ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "model = AutoModelForImageClassification.from_pretrained(MODEL_PATH)\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: {device})\")\n",
    "print(f\"ğŸ“‹ í´ë˜ìŠ¤ ì •ë³´: 5ê°œ êµí†µ í‘œì§€íŒ í´ë˜ìŠ¤ (Class 0 ~ Class 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“¥ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±\n",
    "test_dataset = TrafficSignDataset('data/images/test', processor=None)\n",
    "\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(test_dataset)}ì¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ í‰ê°€ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” í‰ê°€ ì‹œì‘...\\n\")\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for item in test_dataset:\n",
    "        image = item['image']\n",
    "        label = item['label']\n",
    "        \n",
    "        # ì „ì²˜ë¦¬\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # ì˜ˆì¸¡\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        all_predictions.append(predictions.cpu().item())\n",
    "        all_labels.append(label)\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(\"âœ… í‰ê°€ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ì„±ëŠ¥\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    all_labels, all_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== ì „ì²´ ì„±ëŠ¥ (Overall Performance) ===\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nğŸ“Š Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ğŸ“Š Precision: {precision:.4f}\")\n",
    "print(f\"ğŸ“Š Recall: {recall:.4f}\")\n",
    "print(f\"ğŸ“Š F1-Score: {f1:.4f}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (Per-Class Performance) ===\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "precision_per_class, recall_per_class, f1_per_class, support = precision_recall_fscore_support(\n",
    "    all_labels, all_predictions, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nğŸ“Œ Class {i}:\")\n",
    "    print(f\"   - Precision: {precision_per_class[i]:.4f}\")\n",
    "    print(f\"   - Recall: {recall_per_class[i]:.4f}\")\n",
    "    print(f\"   - F1-Score: {f1_per_class[i]:.4f}\")\n",
    "    print(f\"   - Support: {support[i]}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix ê³„ì‚°\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[f'Class {i}' for i in range(5)],\n",
    "            yticklabels=[f'Class {i}' for i in range(5)])\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# ì €ì¥\n",
    "os.makedirs('runs/classification_val', exist_ok=True)\n",
    "plt.savefig('runs/classification_val/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Confusion Matrix ì €ì¥: runs/classification_val/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸ ===\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "target_names = [f'Class {i}' for i in range(5)]\n",
    "report = classification_report(all_labels, all_predictions, \n",
    "                               target_names=target_names, \n",
    "                               zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥\n",
    "from datetime import datetime\n",
    "\n",
    "results_file = 'runs/classification_val/test_results.txt'\n",
    "\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Traffic Sign Classification - í‰ê°€ ê²°ê³¼\\n\")\n",
    "    f.write(f\"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}\\n\")\n",
    "    f.write(f\"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(all_labels)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== Overall Performance ===\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "    f.write(f\"F1-Score: {f1:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== Per-Class Performance ===\\n\")\n",
    "    for i in range(5):\n",
    "        f.write(f\"\\nClass {i}:\\n\")\n",
    "        f.write(f\"  Precision: {precision_per_class[i]:.4f}\\n\")\n",
    "        f.write(f\"  Recall: {recall_per_class[i]:.4f}\\n\")\n",
    "        f.write(f\"  F1-Score: {f1_per_class[i]:.4f}\\n\")\n",
    "        f.write(f\"  Support: {support[i]}\\n\")\n",
    "    \n",
    "    f.write(\"\\n=== Classification Report ===\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {results_file}\")\n",
    "print(f\"\\në‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"  - 03_visualize.ipynbì—ì„œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
