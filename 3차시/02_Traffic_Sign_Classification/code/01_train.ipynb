{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Traffic Sign Classification - ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Hugging Faceì˜ ì‚¬ì „í•™ìŠµëœ CNN ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ êµí†µí‘œì§€íŒì„ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## í•™ìŠµ ê³¼ì •\n",
    "1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "2. Google Drive ë§ˆìš´íŠ¸ ë° ë°ì´í„° ë¡œë“œ\n",
    "3. ë¡œì»¬ì— ì €ì¥ëœ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "4. ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ë° Fine-tuning\n",
    "5. í•™ìŠµ ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face transformers ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install transformers pillow torch torchvision accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Drive ë§ˆìš´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "\n",
    "**ì¤‘ìš”**: ì•„ë˜ ê²½ë¡œë¥¼ ë³¸ì¸ì˜ Google Drive êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive ë‚´ ì‘ì—… ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "WORK_DIR = '/content/drive/MyDrive/2026_AI_Advanced_Study-main/3ì°¨ì‹œ/02_Traffic_Sign_Classification'\n",
    "\n",
    "# ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ í™•ì¸\n",
    "DATA_DIR = Path('data/images')\n",
    "if DATA_DIR.exists():\n",
    "    print(f\"âœ… ë°ì´í„° ë””ë ‰í† ë¦¬ ë°œê²¬: {DATA_DIR}\")\n",
    "else:\n",
    "    print(f\"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDataset(TorchDataset):\n",
    "    \"\"\"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, processor=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.processor = processor\n",
    "        self.samples = []\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ì§‘\n",
    "        for class_idx in range(5):\n",
    "            class_dir = self.data_dir / f'class_{class_idx}'\n",
    "            if class_dir.exists():\n",
    "                for img_path in sorted(class_dir.glob('*.jpg')):\n",
    "                    self.samples.append((img_path, class_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # ì „ì²˜ë¦¬ ì ìš©\n",
    "        if self.processor is not None:\n",
    "            inputs = self.processor(images=image, return_tensors='pt')\n",
    "            # ë°°ì¹˜ ì°¨ì› ì œê±°\n",
    "            pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "            return {'pixel_values': pixel_values, 'label': label}\n",
    "        else:\n",
    "            return {'image': image, 'label': label}\n",
    "\n",
    "print(\"âœ… ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì˜ Image Processor ë¡œë“œ\n",
    "MODEL_NAME = \"google/mobilenet_v2_1.0_224\"  # ê°„ë‹¨í•œ CNN ëª¨ë¸\n",
    "\n",
    "print(f\"ğŸ“¦ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ ë¡œë“œ: {MODEL_NAME}\")\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(\"âœ… ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë°ì´í„°ì…‹ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“¥ ë¡œì»¬ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...\\n\")\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "train_dataset = TrafficSignDataset('data/images/train', processor=processor)\n",
    "val_dataset = TrafficSignDataset('data/images/val', processor=processor)\n",
    "test_dataset = TrafficSignDataset('data/images/test', processor=processor)\n",
    "\n",
    "print(f\"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"  - Train: {len(train_dataset)}ì¥\")\n",
    "print(f\"  - Val: {len(val_dataset)}ì¥\")\n",
    "print(f\"  - Test: {len(test_dataset)}ì¥\")\n",
    "print(f\"\\nğŸ“‹ í´ë˜ìŠ¤ ì •ë³´: 5ê°œ êµí†µ í‘œì§€íŒ í´ë˜ìŠ¤ (Class 0 ~ Class 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ ë¡œë“œ ë° ì„¤ì •\n",
    "\n",
    "Hugging Faceì˜ ì‚¬ì „í•™ìŠµëœ MobileNetV2 ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , 5ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ ë ˆì´ì–´ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ\n",
    "print(f\"ğŸ¤– ëª¨ë¸ ë¡œë“œ: {MODEL_NAME}\")\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=5,  # 5ê°œ í´ë˜ìŠ¤\n",
    "    id2label={i: f\"Class {i}\" for i in range(5)},\n",
    "    label2id={f\"Class {i}\": i for i in range(5)},\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. í•™ìŠµ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ë©”íŠ¸ë¦­ ì •ì˜\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# í•™ìŠµ ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='runs/classification',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=1e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    logging_dir='runs/classification/logs',\n",
    "    logging_strategy='epoch',  # Epoch ë‹¨ìœ„ë¡œ ë¡œê·¸ ê¸°ë¡\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "print(\"=== í•™ìŠµ ì„¤ì • ===\")\n",
    "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Batch Size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Learning Rate: {training_args.learning_rate}\")\n",
    "print(f\"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer ì´ˆê¸°í™”\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ í•™ìŠµ ì‹œì‘...\\n\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"í•™ìŠµëœ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: runs/classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. í•™ìŠµ ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ëª¨ë¸ ì €ì¥\n",
    "trainer.save_model('runs/classification/final_model')\n",
    "processor.save_pretrained('runs/classification/final_model')\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ë° ì„¤ì • ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"\\në‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"  1. 02_test.ipynbì—ì„œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\")\n",
    "print(\"  2. 03_visualize.ipynbì—ì„œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. í•™ìŠµ ê³¡ì„  ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# í•™ìŠµ ë¡œê·¸ ë¡œë“œ\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "# Epoch ë‹¨ìœ„ë¡œ ê¸°ë¡ëœ ë¡œê·¸ë§Œ ì¶”ì¶œ\n",
    "train_logs = [log for log in log_history if 'loss' in log and 'epoch' in log and 'eval_loss' not in log]\n",
    "eval_logs = [log for log in log_history if 'eval_loss' in log]\n",
    "\n",
    "if len(eval_logs) > 0:\n",
    "    # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss ê·¸ë˜í”„ (Epoch ê¸°ì¤€)\n",
    "    train_loss = [log['loss'] for log in train_logs]\n",
    "    eval_loss = [log['eval_loss'] for log in eval_logs]\n",
    "    epochs = list(range(1, len(eval_loss) + 1))\n",
    "    \n",
    "    axes[0].plot(epochs, train_loss, label='Train Loss', marker='o')\n",
    "    axes[0].plot(epochs, eval_loss, label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy ê·¸ë˜í”„ (Epoch ê¸°ì¤€)\n",
    "    eval_acc = [log['eval_accuracy'] for log in eval_logs]\n",
    "    axes[1].plot(epochs, eval_acc, label='Validation Accuracy', marker='s', color='green')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('runs/classification/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… í•™ìŠµ ê³¡ì„  ì €ì¥: runs/classification/training_curves.png\")\n",
    "else:\n",
    "    print(\"âš ï¸ í‰ê°€ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
