{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Traffic Sign Classification - ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì‹œê°í™” ê³¼ì •\n",
    "1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "2. Google Drive ë§ˆìš´íŠ¸ ë° ëª¨ë¸ ë¡œë“œ\n",
    "3. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "4. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” (ê° í´ë˜ìŠ¤ë‹¹ 4ì¥ì”©)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install transformers pillow torch matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Drive ë§ˆìš´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì‘ì—… ë””ë ‰í† ë¦¬ ë° ëª¨ë¸ ë¡œë“œ\n",
    "\n",
    "**ì¤‘ìš”**: `WORK_DIR`ì„ ë³¸ì¸ì˜ Google Drive ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive ë‚´ ì‘ì—… ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
    "WORK_DIR = '/content/drive/MyDrive/2026_AI_Advanced_Study-main/3ì°¨ì‹œ/02_Traffic_Sign_Classification'\n",
    "\n",
    "# ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "\n",
    "# í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ê³ ì •)\n",
    "MODEL_PATH = 'runs/classification/final_model'\n",
    "\n",
    "# ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "print(f\"\\nğŸ¤– ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "model = AutoModelForImageClassification.from_pretrained(MODEL_PATH)\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: {device})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDataset(TorchDataset):\n",
    "    \"\"\"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, processor=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.processor = processor\n",
    "        self.samples = []\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ìˆ˜ì§‘\n",
    "        for class_idx in range(5):\n",
    "            class_dir = self.data_dir / f'class_{class_idx}'\n",
    "            if class_dir.exists():\n",
    "                for img_path in sorted(class_dir.glob('*.jpg')):\n",
    "                    self.samples.append((img_path, class_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        return {'image': image, 'label': label}\n",
    "\n",
    "print(\"âœ… ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“¥ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±\n",
    "test_dataset = TrafficSignDataset('data/images/test', processor=None)\n",
    "\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(test_dataset)}ì¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "ê° í´ë˜ìŠ¤ì—ì„œ 4ì¥ì”© ì„ íƒí•˜ì—¬ ì´ 20ì¥ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "- ë…¹ìƒ‰ ì œëª©: ì˜ˆì¸¡ ì„±ê³µ âœ…\n",
    "- ë¹¨ê°„ìƒ‰ ì œëª©: ì˜ˆì¸¡ ì‹¤íŒ¨ âŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs('runs/classification_pred', exist_ok=True)\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜\n",
    "print(\"ğŸ” í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ë¶„ë¥˜ ì¤‘...\")\n",
    "samples_by_class = {i: [] for i in range(5)}\n",
    "for idx in range(len(test_dataset)):\n",
    "    item = test_dataset[idx]\n",
    "    label = item['label']\n",
    "    samples_by_class[label].append(idx)\n",
    "\n",
    "# ê° í´ë˜ìŠ¤ì—ì„œ 4ì¥ì”© ì„ íƒ (ì´ 20ì¥)\n",
    "selected_indices = []\n",
    "for class_idx in range(5):\n",
    "    class_samples = samples_by_class[class_idx]\n",
    "    num_to_select = min(4, len(class_samples))\n",
    "    selected_indices.extend(class_samples[:num_to_select])\n",
    "\n",
    "print(f\"ğŸ“Š ì‹œê°í™”í•  ì´ë¯¸ì§€: {len(selected_indices)}ì¥ (ê° í´ë˜ìŠ¤ë‹¹ 4ì¥)\\n\")\n",
    "\n",
    "# 5Ã—4 ê·¸ë¦¬ë“œë¡œ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(5, 4, figsize=(16, 20))\n",
    "\n",
    "for plot_idx, sample_idx in enumerate(selected_indices):\n",
    "    row = plot_idx // 4\n",
    "    col = plot_idx % 4\n",
    "    \n",
    "    item = test_dataset[sample_idx]\n",
    "    image = item['image']\n",
    "    true_label = item['label']\n",
    "    \n",
    "    # ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        pred_label = torch.argmax(outputs.logits, dim=-1).cpu().item()\n",
    "        confidence = torch.softmax(outputs.logits, dim=-1)[0][pred_label].cpu().item()\n",
    "    \n",
    "    # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "    axes[row, col].imshow(image)\n",
    "    axes[row, col].axis('off')\n",
    "    \n",
    "    # ì œëª© ìƒ‰ìƒ (ë§ìœ¼ë©´ ë…¹ìƒ‰, í‹€ë¦¬ë©´ ë¹¨ê°„ìƒ‰)\n",
    "    color = 'green' if pred_label == true_label else 'red'\n",
    "    title = f\"True: Class {true_label}\\nPred: Class {pred_label}\\nConf: {confidence:.2f}\"\n",
    "    axes[row, col].set_title(title, fontsize=10, color=color, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('runs/classification_pred/predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì™„ë£Œ: runs/classification_pred/predictions.png\")\n",
    "print(f\"   ê° í´ë˜ìŠ¤ë‹¹ 4ì¥ì”©, ì´ {len(selected_indices)}ì¥ ì‹œê°í™”\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
