{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b0e46f",
   "metadata": {},
   "source": [
    "## ğŸ¯ YOLO Pose Estimation Demo\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” í•™ìŠµëœ YOLO Pose ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬\n",
    "1. ğŸ“¸ **ì´ë¯¸ì§€**ì—ì„œ í¬ì¦ˆ ì˜ˆì¸¡\n",
    "2. ğŸ“¹ **ì›¹ìº **ìœ¼ë¡œ ì‹¤ì‹œê°„ í¬ì¦ˆ ì˜ˆì¸¡\n",
    "\n",
    "---\n",
    "#### 1ï¸âƒ£  í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a307415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a87ab",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2ï¸âƒ£ YOLO ëª¨ë¸ ë¡œë“œ\n",
    "\n",
    "- í•™ìŠµí•œ `ëª¨ë¸ì˜ ê²½ë¡œ`ë¥¼ ì…ë ¥í•´ ë³´ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ê²½ë¡œ ì„¤ì •\n",
    "# ex) MODEL_PATH = 'runs/pose/train/weights/best.pt'\n",
    "MODEL_PATH = ''\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "try:\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {MODEL_PATH}\")\n",
    "    print(f\"ğŸ“Š ëª¨ë¸ ì •ë³´: {model.info()}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ ëª¨ë¸ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e778e",
   "metadata": {},
   "source": [
    "---\n",
    "#### ğŸ“¸ Part 1: ì´ë¯¸ì§€ì—ì„œ í¬ì¦ˆ ì˜ˆì¸¡\n",
    "\n",
    "ë‹¨ì¼ ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ í¬ì¦ˆë¥¼ ê°ì§€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ì˜ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)\n",
    "# image_path = '../data_10%/demo/demo_1.jpg'\n",
    "image_path = ''  # â† ì—¬ê¸°ì— í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# ì´ë¯¸ì§€ ì˜ˆì¸¡\n",
    "if os.path.exists(image_path):\n",
    "    results = model.predict(source=image_path, conf=0.5, save=False, verbose=False)\n",
    "    # ê²°ê³¼ ì‹œê°í™”\n",
    "    for result in results:\n",
    "        \n",
    "        img_with_pose = result.plot()  # í¬ì¦ˆê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€\n",
    "\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(cv2.cvtColor(img_with_pose, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title('Pose Estimation Result', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # ê°ì§€ëœ keypoints ì •ë³´ ì¶œë ¥\n",
    "        if result.keypoints is None:\n",
    "            print(\"\\nâŒ í¬ì¦ˆê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")      \n",
    "else:\n",
    "    print(f\"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}\")\n",
    "    print(\"ğŸ’¡ image_path ë³€ìˆ˜ë¥¼ ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99968af",
   "metadata": {},
   "source": [
    "---\n",
    "#### ğŸ“¹ Part 2: ì›¹ìº ìœ¼ë¡œ ì‹¤ì‹œê°„ í¬ì¦ˆ ì˜ˆì¸¡\n",
    "\n",
    "ì›¹ìº ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ í¬ì¦ˆë¥¼ ê°ì§€í•©ë‹ˆë‹¤.\n",
    "\n",
    "âš ï¸ **ì£¼ì˜ì‚¬í•­:**\n",
    "- ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- Jupyter í™˜ê²½ì— ë”°ë¼ ì‹¤í–‰ì´ ì•ˆ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webcam_pose_detection(conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    ì›¹ìº ìœ¼ë¡œ ì‹¤ì‹œê°„ í¬ì¦ˆ ê°ì§€\n",
    "    \n",
    "    Args:\n",
    "        conf_threshold: confidence threshold (ê¸°ë³¸ê°’: 0.5)\n",
    "    \n",
    "    ì¢…ë£Œ: 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(0)  # 0ì€ ê¸°ë³¸ ì›¹ìº \n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nğŸ¥ ì›¹ìº  ì‹¤í–‰ ì¤‘...\")\n",
    "    print(\"ğŸ“ ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”!\")\n",
    "    print(\"ğŸ“ ìŠ¤í¬ë¦°ìƒ·ì„ ì°ìœ¼ë ¤ë©´ 's' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”!\\n\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    screenshot_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                break\n",
    "            \n",
    "            # YOLO ì˜ˆì¸¡\n",
    "            results = model.predict(source=frame, conf=conf_threshold, save=False, verbose=False)\n",
    "            \n",
    "            # ê²°ê³¼ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "            annotated_frame = results[0].plot()\n",
    "            \n",
    "            # FPS ê³„ì‚° ë° í‘œì‹œ\n",
    "            frame_count += 1\n",
    "            cv2.putText(annotated_frame, f'Frame: {frame_count}', (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # ê°ì§€ëœ ì‚¬ëŒ ìˆ˜ í‘œì‹œ\n",
    "            if results[0].keypoints is not None:\n",
    "                num_people = len(results[0].keypoints)\n",
    "                cv2.putText(annotated_frame, f'People: {num_people}', (10, 70),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # í™”ë©´ì— í‘œì‹œ\n",
    "            cv2.imshow('YOLO Pose Detection - Press Q to quit, S for screenshot', annotated_frame)\n",
    "            \n",
    "            # í‚¤ ì…ë ¥ ì²˜ë¦¬\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                print(\"\\nğŸ‘‹ ì›¹ìº  ì¢…ë£Œ\")\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                # ìŠ¤í¬ë¦°ìƒ· ì €ì¥\n",
    "                screenshot_filename = f'screenshot_{screenshot_count:03d}.jpg'\n",
    "                cv2.imwrite(screenshot_filename, annotated_frame)\n",
    "                print(f\"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_filename}\")\n",
    "                screenshot_count += 1\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâš ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"\\nâœ… ì´ {frame_count} í”„ë ˆì„ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "        print(f\"ğŸ“¸ ì´ {screenshot_count}ê°œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥\")\n",
    "\n",
    "# ì›¹ìº  ì‹¤í–‰\n",
    "# run_webcam_pose_detection(conf_threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAMUS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
